{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2d508b5",
   "metadata": {},
   "source": [
    "## OCR_심화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e4e1e7",
   "metadata": {},
   "source": [
    "### TrOCR 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36d06fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.8.0-cp312-none-macosx_11_0_arm64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: filelock in /Users/apple/.pyenv/versions/3.12.11/lib/python3.12/site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/apple/.pyenv/versions/3.12.11/lib/python3.12/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /Users/apple/.pyenv/versions/3.12.11/lib/python3.12/site-packages (from torch) (80.9.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: fsspec in /Users/apple/.pyenv/versions/3.12.11/lib/python3.12/site-packages (from torch) (2025.9.0)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/apple/.pyenv/versions/3.12.11/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torch-2.8.0-cp312-none-macosx_11_0_arm64.whl (73.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, sympy, networkx, jinja2, torch\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [torch]32m4/5\u001b[0m [torch]]x]\n",
      "\u001b[1A\u001b[2KSuccessfully installed jinja2-3.1.6 mpmath-1.3.0 networkx-3.5 sympy-1.14.0 torch-2.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a98bd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.56.1-py3-none-any.whl.metadata (42 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Downloading filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/apple/.pyenv/versions/3.12.11/lib/python3.12/site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/apple/.pyenv/versions/3.12.11/lib/python3.12/site-packages (from transformers) (25.0)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Downloading PyYAML-6.0.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2025.9.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /Users/apple/.pyenv/versions/3.12.11/lib/python3.12/site-packages (from transformers) (2.32.5)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.0-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/apple/.pyenv/versions/3.12.11/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Downloading hf_xet-1.1.9-cp37-abi3-macosx_11_0_arm64.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/apple/.pyenv/versions/3.12.11/lib/python3.12/site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/apple/.pyenv/versions/3.12.11/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/apple/.pyenv/versions/3.12.11/lib/python3.12/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/apple/.pyenv/versions/3.12.11/lib/python3.12/site-packages (from requests->transformers) (2025.8.3)\n",
      "Downloading transformers-4.56.1-py3-none-any.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.5/561.5 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.1.9-cp37-abi3-macosx_11_0_arm64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.22.0-cp39-abi3-macosx_11_0_arm64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "Downloading PyYAML-6.0.2-cp312-cp312-macosx_11_0_arm64.whl (173 kB)\n",
      "Downloading regex-2025.9.1-cp312-cp312-macosx_11_0_arm64.whl (287 kB)\n",
      "Downloading safetensors-0.6.2-cp38-abi3-macosx_11_0_arm64.whl (432 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: tqdm, safetensors, regex, pyyaml, hf-xet, fsspec, filelock, huggingface-hub, tokenizers, transformers\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/10\u001b[0m [transformers][0m [transformers]ub]\n",
      "\u001b[1A\u001b[2KSuccessfully installed filelock-3.19.1 fsspec-2025.9.0 hf-xet-1.1.9 huggingface-hub-0.34.4 pyyaml-6.0.2 regex-2025.9.1 safetensors-0.6.2 tokenizers-0.22.0 tqdm-4.67.1 transformers-4.56.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdc8d81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrOCR 모델 데모 start!\n",
      "TrOCR 모델 로딩 중 : microsoft/trocr-base-printed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00, 10082.46it/s]\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-printed and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 로딩 완료(Device:cpu)\n",
      "인식된 텍스트: ['THANKMM']\n",
      "\n",
      "2. 여러 모델 비교\n",
      "모델 사용 중: Base printed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00, 14873.42it/s]\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-printed and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 사용 중: Base handwritten\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00, 6186.29it/s]\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 사용 중: Large printed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00, 9341.43it/s]\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-large-printed and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base printed        : ['THANKMM']\n",
      "Base handwritten    : ['6th.th.']\n",
      "Large printed       : ['***']\n",
      "\n",
      "3. 신뢰도 점수 테스트\n",
      "신뢰도 계산 상세:\n",
      "토큰 확률: ['0.184', '0.542', '0.617', '0.697']\n",
      "평균 신뢰도: 0.510\n",
      "인식된 텍스트: ['THANKMM']\n",
      "신뢰도 점수: 51.0%\n",
      "\n",
      "4. 성능 평가 테스트\n",
      "원본: 'Hello world!'\n",
      "예측: 'HELBWATAL (RM)'\n",
      "정확도: 35.7%\n",
      "\n",
      "원본: 'The quick brown fox jumps over the lazy dog.'\n",
      "예측: 'RECEIPTARYS FOR EXCLUDED ON BACK'\n",
      "정확도: 66.7%\n",
      "\n",
      "원본: 'Machine learning is fascinating.'\n",
      "예측: 'INCHANGE@MANITY ONCLUSIVE OF RECEIPT FOR RECEIPT FOR'\n",
      "정확도: 65.0%\n",
      "\n",
      "원본: '2024 한국어 테스트'\n",
      "예측: '2024MM'\n",
      "정확도: 30.0%\n",
      "\n",
      "원본: 'Mixed 언어 테스트 123!'\n",
      "예측: 'MASITIM: 123- 1 VEGET (RM)'\n",
      "정확도: 25.0%\n",
      "\n",
      "\n",
      "전체 평균 정확도: 44.48%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAACQCAYAAACVtmiTAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAACVNJREFUeJzt3EfIHtUaB/CTGHvH2BLBXtBYsHesKCISAppdli5UVNCNK1cuBLeKK3UjIriLBQtiL9i7WLCX2Hus+S7/A+flvdEbrjfeG7/7/H4wfPPNO3Nm3k/J859zzsycmZmZmQYAlDV3XV8AALBuCQMAUJwwAADFCQMAUJwwAADFCQMAUJwwAADFCQMAUJwwAADFCQMAUJwwAADFCQMAUJwwAADFCQMAUJwwAADFCQMAUJwwAADFCQMAUJwwAADFCQMAUJwwAADFCQMAUJwwAADFCQMAUJwwAADFCQMAUJwwAADFCQMAUJwwAADFCQMAUJwwAADFCQMAUJwwAADFCQMAUJwwAADFCQMAUJwwAADFCQMAUJwwAADFCQMAUJwwAADFCQMAUJwwAADFCQMAUJwwAADFCQMAUJwwAADFzVvXF/B3NjMz01atWtWXrI9tc+bM6etz586dLH903G+//TbZlmOy33rrrdd/H+1mGZ/ns/zMkjZ+/vnnybmGefPmTfYBgL+CMLAGKci33XZbu+mmm9qnn37avvnmm/byyy+3I444ohfj4447rp1yyintmGOO+afj3nnnnXbHHXe0G264oW2wwQbt119/bXvvvXc766yz2pIlS/o+d911V7vzzjvbo48+2jbddNO+XHLJJe2ggw5qW265Zfvll1/awoUL21577dU23njjHizSzhVXXNEOO+ywtskmm6yjvwoA/2/mzIxbXn4nf5qvvvqqffHFF70QP/PMM+3CCy9s999/f7/L32yzzdoWW2zRNt9888kxb7zxRnvwwQfbPffc0/fNZz/++GN76qmn2kMPPdTOO++83u4tt9zS5s+f304//fS20UYbtSeeeKI9/fTTPWAkMKRXYMcdd2zXX399DxI//PBDe+utt9p1113Xrr322rbTTju1hx9+uAeIhJH0KqSX4ZNPPumBJY4++ui24YYb9vXvv/++n+Pee+/t13TzzTe3q6++ugeLHJuwkRDz9ttv9+927LHH9l6ItPnll1+25557rrdz+OGH9+ASP/30U3vkkUfarbfe2nbYYYd18t8IgLWnZ2ANcve/9dZb9yU+//zzXiBztz66+9988812zTXX9G3bbbdde/HFF9uHH37YDj744HbggQf2Ypy7/BTbbL/99tt7u1tttVXvBVi0aFFva/311+8Fd+XKlZPhhRTlnXfeuYeBhINcx6WXXtrXRzFO8U97BxxwQG///fffbytWrOiBI8see+zRC3quK9vHsETCwWeffdbPkWt97bXX+rmzzxiG2HfffXsQyPcebeback0JMKPN6eEQAGYfYWAtJQxcddVVbdmyZb245+473frnnHNOL5iRoYLdd9+9321ffvnlvdBecMEFbf/99+/hIvJ5CvqCBQsm8xOmpWiPu/whQwW77rprDyKnnnpqe/XVV3tBTyhIG3vuuWc7/vjjJ3MeUrxHiEmPxm677daPTe9EegvSC/Ltt9/268uxJ510Um8rYSbfc7SZHoccH+nNGN8BgNnJv+JradyBn3baab2LP8MB3333XS/u01I8c0edrv7YZpttek/CtASKYdz9Z3gi67lDf/zxx/t8hemQkTby+yuvvNLv0LfffvtJuwkl7777bg8R2b7ttttOJh4mSGSYIp+98MIL/WeOy5J90maGPLI+3WaO+/jjj3toGNtXn0AJwOziX/G1lGKZQnriiSdOivS/Mu74p59OWJOEgPQgJGiceeaZ7aKLLmpXXnllL+pDhheWLl3abrzxxn4t6W0YFi9e3O/cU+xXn+Q4Akp6MDJ3ID0SGVKIFPdsz1yAzJc49NBDJ8ecccYZPWA88MAD7YQTTvg3/0oA/J3pGVhL45HA0VWeQp079NxVZz7A8PXXX/cJeukxyFh/xuvzhML0sEAmB+6yyy7t5JNP7r+nzcsuu6x35X/00Ue9OOcJhLPPPrvPOYh04eeJhyOPPHIyyXC4++67e/vpIXjyySd/d+3pwcgchjwR8d577/Xri1xPtidY5LslTAz33Xdfn0CYIPHYY4/91/6uAPzv6Bn4C4yu9zHpLkMAebQwTxGM9wVkzD1PE6TwZhw/E/aef/75yeS7l156qW/LZL1hTCDcZ599emHOEEGOSZgYQwgJGem2P+SQQ3rhznoegcz2TO7LvIAEgkwszPYRPHJNmSOQfY466qg+1yCTEcexaSdhJk9MfPDBB5Pt2SdPOSTUJEBMtwnA7KRn4C+WSYApkHmPwLPPPtuLaUJB1vPY3vnnn9+L6vLly3sXfsbdM8yQoJCfecfAH8lYfZ4qyKOGKeQpwAkF6TFIgEgQybyCFP0xgTDbExiypHBn3+mnCcaxCREp8uPYtJXtaSPfJdvHsenRyPmzjDY9TQAwuwkDf0Lu1DNpb03bcsec4pou+4zx57MUy3T156VDea4/UlQTGM4999z+yGAm81188cVtv/32m7SVY8fkvASFvFsg4/UZGoic4/XXX+9BIz0LOU/u4rMt8qhi1lPUMySQ9REGEkjye96dkKcMEhjye5acM8fmfQU5NsMZ6bWI9Ewk1CQwpDch+4/rAWB28tKhPyGFNEUzk/bG0MAfbZt+jfHqryMexT2FezyJMP359OuIU2QzbyDbx37ZlnON8+Tcq7+aeLrN1beP68z5s0zvM/2/wn/SJgCzkzAAAMWZQAgAxQkDAFCcMAAAxQkDAFCcMAAAxQkDAFCcMAAAxQkDAFCcMAAAxQkDAFCcMAAAxQkDAFCcMAAAxQkDAFCcMAAAxQkDAFCcMAAAxQkDAFCcMAAAxQkDAFCcMAAAxQkDAFCcMAAAxQkDAFCcMAAAxQkDAFCcMAAAxQkDAFCcMAAAxQkDAFCcMAAAxQkDAFCcMAAAxQkDAFCcMAAAxQkDAFCcMAAAxQkDAFCcMAAAxQkDAFCcMAAAxQkDAFCcMAAAxQkDAFCcMAAAxQkDAFCcMAAAxQkDAFCcMAAAxQkDAFCcMAAAxQkDAFCcMAAAxQkDAFCcMAAAxQkDAFCcMAAAxQkDAFCcMAAAxQkDAFCcMAAAxQkDAFCcMAAAxQkDAFCcMAAAxQkDAFCcMAAAxQkDAFCcMAAAxQkDAFCcMAAAxQkDAFCcMAAAxQkDAFCcMAAAxQkDAFCcMAAAxQkDAFCcMAAAxQkDAFCcMAAAxQkDAFCcMAAArbZ/AJnX3YPeC1puAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import requests\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class TrOCRsystem:\n",
    "    def __init__(self, model_name='microsoft/trocr-base-printed'):\n",
    "        print(f\"TrOCR 모델 로딩 중 : {model_name}\")\n",
    "        self.processor = TrOCRProcessor.from_pretrained(model_name)\n",
    "        self.model = VisionEncoderDecoderModel.from_pretrained(model_name)\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model.to(self.device)\n",
    "        print(f\"모델 로딩 완료(Device:{self.device})\")\n",
    "        \n",
    "    def extract_image(self, image, return_confidence=False):\n",
    "        # PIL 이미지로 변환\n",
    "        if isinstance(image, np.ndarray):\n",
    "            image = Image.fromarray(image)\n",
    "        elif isinstance(image, str):\n",
    "            if image.startswith(('http://', 'https://')):\n",
    "                image = Image.open(requests.get(image, stream=True).raw)\n",
    "            else: \n",
    "                image = Image.open(image)\n",
    "        \n",
    "        pixel_values = self.processor(images=image, return_tensors=\"pt\").pixel_values\n",
    "        pixel_values = pixel_values.to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            if return_confidence:\n",
    "                outputs = self.model.generate(\n",
    "                    pixel_values,\n",
    "                    return_dict_in_generate=True,\n",
    "                    output_scores=True,\n",
    "                    max_length=256\n",
    "                )\n",
    "                generated_ids = outputs.sequences\n",
    "                token_scores = outputs.scores\n",
    "                generated_text = self.processor.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "            else:\n",
    "                generated_ids = self.model.generate(pixel_values)\n",
    "                generated_text = self.processor.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "            \n",
    "        if return_confidence:\n",
    "            if token_scores:\n",
    "                token_probs = []\n",
    "                for score in token_scores:\n",
    "                    probs = torch.softmax(score, dim=-1)\n",
    "                    max_prob = torch.max(probs).item()\n",
    "                    token_probs.append(max_prob)\n",
    "                confidence = sum(token_probs) / len(token_probs) if token_probs else 0.0\n",
    "                print(\"신뢰도 계산 상세:\")\n",
    "                print(f\"토큰 확률: {[f'{p:.3f}' for p in token_probs]}\")\n",
    "                print(f\"평균 신뢰도: {confidence:.3f}\")\n",
    "            else:\n",
    "                confidence = 0.5\n",
    "                print(\"실제 확률 정보 없음, 기본값 사용\")\n",
    "            return generated_text, confidence\n",
    "            \n",
    "        return generated_text\n",
    "    \n",
    "    def batch_extract(self, images):\n",
    "        results = []\n",
    "        for i, image in enumerate(images):\n",
    "            print(f\"처리중 : {i+1}/{len(images)}\")\n",
    "            try:\n",
    "                text = self.extract_image(image)\n",
    "                results.append(text)\n",
    "            except Exception as e:\n",
    "                print(f\"이미지 {i+1} 처리 중 오류 발생: {e}\")\n",
    "                results.append(\"\")\n",
    "        return results\n",
    "    \n",
    "    def compare_models(self, image):\n",
    "        models = {\n",
    "            'Base printed': 'microsoft/trocr-base-printed',\n",
    "            'Base handwritten': 'microsoft/trocr-base-handwritten',\n",
    "            'Large printed': 'microsoft/trocr-large-printed'\n",
    "        }\n",
    "        results = {}\n",
    "        for model_name, model_path in models.items():\n",
    "            try:\n",
    "                print(f\"모델 사용 중: {model_name}\")\n",
    "                temp_processor = TrOCRProcessor.from_pretrained(model_path)\n",
    "                temp_model = VisionEncoderDecoderModel.from_pretrained(model_path)\n",
    "                temp_model.to(self.device)\n",
    "                pixel_values = temp_processor(images=image, return_tensors=\"pt\").pixel_values.to(self.device)\n",
    "                with torch.no_grad():\n",
    "                    generated_ids = temp_model.generate(pixel_values)\n",
    "                text = temp_processor.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "                results[model_name] = text\n",
    "                del temp_model, temp_processor\n",
    "                torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "            except Exception as e:\n",
    "                print(f\"모델 {model_name} 처리 중 오류 발생: {e}\")\n",
    "                results[model_name] = f\"Error: {str(e)}\"\n",
    "        return results\n",
    "\n",
    "# 전역 함수 정의\n",
    "\n",
    "def create_sample_trocr_image(handwritten=False):\n",
    "    img = Image.new('RGB', (400,100), 'white')\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", 24)\n",
    "    except IOError:\n",
    "        font = ImageFont.load_default()\n",
    "    text = \"TrOCR 모델 테스트\" if not handwritten else \"손글씨 테스트\"\n",
    "    draw.text((50, 30), text, font=font, fill='black')\n",
    "    img.save(\"sample_trocr_image.png\")\n",
    "    return img\n",
    "\n",
    "def create_test_image(text):\n",
    "    img_width = len(text) * 20 + 100\n",
    "    img_height = 60\n",
    "    img = Image.new('RGB', (img_width, img_height), 'white')\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", 24)\n",
    "    except OSError:\n",
    "        font = ImageFont.load_default()\n",
    "    draw.text((20,20), text, font=font, fill='black')\n",
    "    return img\n",
    "\n",
    "def calculate_simple_accuracy(ground_truth, predicted):\n",
    "    if not ground_truth or not predicted:\n",
    "        return 0.0\n",
    "    gt_chars = set(ground_truth.lower().replace(\" \", \"\"))\n",
    "    pred_chars = set(predicted.lower().replace(\" \", \"\"))\n",
    "    if len(gt_chars) == 0:\n",
    "        return 1.0 if len(pred_chars) == 0 else 0.0\n",
    "    intersection = len(gt_chars.intersection(pred_chars))\n",
    "    union = len(gt_chars.union(pred_chars))\n",
    "    return intersection / union if union > 0 else 0.0\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 데모 실행\n",
    "    print(\"TrOCR 모델 데모 start!\")\n",
    "    ocr = TrOCRsystem()\n",
    "\n",
    "    # 1. 로컬 이미지 생성 후 테스트\n",
    "    sample_image = create_sample_trocr_image()\n",
    "    text = ocr.extract_image(sample_image)\n",
    "    print(f\"인식된 텍스트: {text}\")\n",
    "\n",
    "    # 2. 여러 모델 결과 비교\n",
    "    print(\"\\n2. 여러 모델 비교\")\n",
    "    comparison = ocr.compare_models(sample_image)\n",
    "    for model_name, result in comparison.items():\n",
    "        print(f\"{model_name:20}: {result}\")\n",
    "\n",
    "    # 3. 신뢰도 점수 테스트\n",
    "    print(\"\\n3. 신뢰도 점수 테스트\")\n",
    "    text, confidence = ocr.extract_image(sample_image, return_confidence=True)\n",
    "    print(f\"인식된 텍스트: {text}\")\n",
    "    print(f\"신뢰도 점수: {confidence:.1%}\")\n",
    "\n",
    "    # 4. 성능 평가용 테스트 케이스\n",
    "    print(\"\\n4. 성능 평가 테스트\")\n",
    "    test_cases = [\n",
    "        \"Hello world!\",\n",
    "        \"The quick brown fox jumps over the lazy dog.\",\n",
    "        \"Machine learning is fascinating.\",\n",
    "        \"2024 한국어 테스트\",\n",
    "        \"Mixed 언어 테스트 123!\"\n",
    "    ]\n",
    "    accuracies = []\n",
    "    for test_text in test_cases:\n",
    "        test_image = create_test_image(test_text)\n",
    "        predicted = ocr.extract_image(test_image)\n",
    "        \n",
    "        # predicted가 리스트면 첫 원소 사용\n",
    "        if isinstance(predicted, list):\n",
    "            predicted = predicted[0] if predicted else \"\"\n",
    "        \n",
    "        accuracy = calculate_simple_accuracy(test_text, predicted)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        print(f\"원본: '{test_text}'\\n예측: '{predicted}'\\n정확도: {accuracy:.1%}\\n\")\n",
    "    avg_accuracy = sum(accuracies) / len(accuracies) if accuracies else 0.0\n",
    "    print(f\"\\n전체 평균 정확도: {avg_accuracy:.2%}\")\n",
    "\n",
    "    # 이미지 예시 시각화\n",
    "    plt.imshow(sample_image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5a38dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
